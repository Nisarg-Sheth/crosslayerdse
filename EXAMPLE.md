#Explaination of code with example

The current framework consists of 4 major components pre-processing of input tgff data, the ILP problem formulator, the PB Solver and the Meta-Heuristic.

### Pre-processing of the input tgff data

For the purpose of our example we will use the a.tgff a scenario from the e3s benchmark.

The e3s benchmark consists of 17 different client processing elements (CLIENT_PE). The task specific information for each Processing Element(PE) is present in each \*.tgff file seperately.
The scenario consists of 4 different application task graph.

Each task graph and task-specific data for each CLIENT_PE is present in individual blocks.

`get_blocks` :

The `get_blocks` function processes the .tgff file and isolates each block in the file, which could be either a task graph or a processing element.
1)Input : \*.tgff file
2)Output : a single block stored line-by-line in a list

`process_block` :

The `process_block` function takes this isolated block as input and adds the appropriate `graph` or `all_tables` to the `scenario` class.
1)Input : List
2)Output : Initialize the individual `graph` and `all_tables` to the `scenario` class.

`generate_noc` :

This evaluates the `all_tables` dictionary and outputs a random NOC and populates the `tables` dictionary with these values.
1) Input : Width, breadth
2) Output : Populate `tables` with the random CLIENT_PEs included in the NOC
            Generates a random NOC and adds it to `scenario.NOC`

`populate_task_params` :

The `populate_task_params` function is used to populate the tasks with the list of the valid processing elements and other PE specific details such as WCET, power and pre-emption time.
1)Input : `tables` (which contains CLIENT_PE)
2)Output : Populate the PE specific values in the class Task.
This function essentially coverts the mapping CLIENT_PE ---> Task to Task--->CLIENT_PE

Sample output for TASK_GRAPH 0 is as follows :

```
Graph name is  TASK_GRAPH 0
Number of tasks in Graph is 6
Task 1  is src
List of PEs it can be scheduled on is:
Task 2  is can1
Task 3  is fp
Task 4  is can2
Task 5  is pulse
Task 6  is sink
Number of Messages in Graph is  5
Arc 1 is a0_01 between :
src ---> can1
Arc 2 is a0_12 between :
can1 ---> fp
Arc 3 is a0_13 between :
fp ---> can2
Arc 4 is a0_24 between :
can2 ---> pulse
Arc 5 is a0_35 between :
pulse ---> sink
```
*add link to x.txt **
Detailed output at the end of the pre-processing can be seen in the output file x.txt.

`print_app_graph(graph)` can be uncommented to print this.

`plot_app_graph`

This function plots the application graph stored in the Class Graph.
1) Input : Class Graph
2) Output : .png file with the task graph plotted.

*add link to app_graph_plot0.view **
The plots of the application graphs generated by this approach can be seen in the file ./lp_files as app_graph_plot0.view

## PB Problem Generation and Solving

### ILP problem formulator.

Now that we have processed the input we can use the input data to generate the constraints.

The process for generating the constraints is similar regardless of whether we generate an .lp file a .opb file or internal values.

For the ILP formulator and the PB solver we will pick one single task graph as an example from the benchmark. In the benchmark the `TASK_GRAPH0` is the example output we will consider for the coming examples.

`gen_comp_pb` :

The `gen_comp_pb` function generates the PB/ILP formulation.
1)Input : Class Graph
2)Output : either .lp file or dictionary containing the formulation.

*ADD OUTPUT link to the ilp formulation.***
We can observe this output in the ./lp_file folder in the ilp_0.lp.

For the case of the DPLL solver based approach the constraint problem is exactly the same the shown the previous method.

In the DPLL solver case we also maintain a Decision strategy that looks something like this. This decision strategy is generated randomly for every individual :-

```
THE DECISION STRATEGY IS AS FOLLOWS
 ------ Variable C_can1_src
Decision Value 0.999549608683551
Decision Priority True
 ------ Variable map_can1_CLIENT_PE4
Decision Value 0.9864450165657144
Decision Priority False
 ------ Variable C_pulse_can1
Decision Value 0.9841263726670819
Decision Priority True
 ------ Variable map_can2_CLIENT_PE3
Decision Value 0.9795964132000818
Decision Priority False
 ------ Variable map_sink_CLIENT_PE9
Decision Value 0.977336828334449
Decision Priority False
 ------ Variable map_can2_CLIENT_PE4
Decision Value 0.9745819954358579
Decision Priority True
 ------ Variable map_src_CLIENT_PE11
Decision Value 0.9703329147617604
Decision Priority False
 ------ Variable pulse_master
Decision Value 0.9646734743732154
...
...
...
```

This decision strategy decides the working of the solver.

### PB Solver
*ADD OUTPUT link to the result0.sol***
In the case that we use the gurobi solver, the assignment can be observed in the result0.sol file.

In the case of the self-implemented solver the result of the assignment is stored in an assignment dictionary where the key is the variable name and the value corresponds to the value assigned to the variable.

`pbs_solver` :

The internal workings of the `pbs_solver` are subject to further change, but the current pseudo code is as follows :

*Add pseudo code of solver here.**

1)Input: Constraints, decision strategy
2)Output: Assignment values to variables

`generate_con_graph` :

The `generate_con_graph` function is used to process the solution generated from either approaches and store the processed approach in a object of the class Constraint_graph.
1) Input : assignment of variables
2) Output : Complete Constraint Graph

`plot_constraint_graph` :

This function plots the constraint graph in a png file.
1)Input : Constraint graph
2)Output : .png file with the task graph plotted.

The constraint graph can be found in the ./lp_files folder as con_graph_plot0.view

*ADD a display of the constraint graph here.**

### DVFS-LEVEL

The current framework takes the dvfs-level of each PE in the system as a command line argument. It can be enabled by using the `--dvfs number` command.

`gen_dvfslevel` :

The `gen_dvfslevel` function is used to generated realistic values for dvfs considering only dynamic power dissipation in the system.
1)Input : Command-line argument
2)Output : Values stored in an dictionary.

These dvfs-levels are then used in the rest of the place including the PB problem formulation, solving and the consequent constraint graph.

The output_with_dvfs_level.txt contains the output.

## Meta-Heuristics

`make_individual` :

This function generates a unique constraint graph using the `gen_comp_pb`,`pbs_solver` and the `generate_con_graph` functions.
In the gurobi files, it generates a new unique .lp file corresponding to each Individual. The naming of the files is managed by using some additional input.

1)Input: Task Graph
2)Output: Individual=Constraint graph.

`make_pop` :

Generates a population of individual. Passes the name of the TASK_GRAPH to the individual.
1)Input: Task Graph
2)Output: List of Individuals

`mutatefunc` :

1)Input : Constraint Graph  = (Decision Strategy)
2)Output : Mutated Constraint Graph.
This mutates the decision strategy of the Constraint graph.
Then the `pbs_solver` is called to solve the problem according to the new decision strategy.
Then the `generate_con_graph` function is called to populate the Constraint graph with the mutated solution.

`matefunc` :

1)Input : 2 Constraint Graphs  = (Decision Strategies)
2)Output : 2 new constraint graphs after cross-over
This function also changes the decision strategy of both the individuals. Then `pbs_solver` and the `generate_con_graph` functions are called on both the constraint graphs.

`evaluatefunc` :

The evaluate function evaluates the solution with respect to throughput and power.

The energy of implementation can be found by adding the energy of execution of each task on the allocated PE type along with the additional energy cost of communication.

For the execution time, a priority based approach can be used.
The priority of a task is determined by its precedence constraints. The lower priority task is always preceded by a higher priority task. This priority consideration aids us in ensuring the high priority task always executes before the low priority task.

Now in a cluster, the priority of the task can also aid in deciding the execution time. The higher priority task sets a lower bound on the start of execution time of the lower priority task. Hence now for a low priority task, the lower bound on execution time is set as max((execution time of all high priority tasks on cluster),(execution times of all tasks that are successors of the low priority task)).
If we iterate over all tasks in the order of their priority while setting the lower bound on start of execution time of lower priority tasks, we can obtain the net execution time of each cluster and subsequently the execution time of the whole application.

1)Input : Individual (Constraint Graph) and Task/Message data from TASK_GRAPH
2)Output : 2 values, the Value of the Power and the execution time.

The evaluate function generates the Task Schedule. We can observe the Task Schedule for a particular task in the particular solution.

*Add print of task schedule here.**
